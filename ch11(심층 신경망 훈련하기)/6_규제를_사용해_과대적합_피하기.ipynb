{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. 규제를 사용해 과대적합 피하기.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0343BzMAYQio"
      },
      "outputs": [],
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju6q8s-4aos1",
        "outputId": "1b40759b-903e-4bc3-8336-a2670bb3b44b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $\\ell_1$과 $\\ell_2$ 규제"
      ],
      "metadata": {
        "id": "9mrG1XSiayi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))"
      ],
      "metadata": {
        "id": "8TA9JTZ9aqqS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(100, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(10, activation=\"softmax\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soDDni7pa-sW",
        "outputId": "a9bc5427-a1a0-4038-81b1-df8f2d85c394"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 16s 9ms/step - loss: 1.5677 - accuracy: 0.8121 - val_loss: 0.7044 - val_accuracy: 0.8364\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.7193 - accuracy: 0.8269 - val_loss: 0.6985 - val_accuracy: 0.8390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "RegularizedDense = partial(keras.layers.Dense,\n",
        "                           activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    RegularizedDense(300),\n",
        "    RegularizedDense(100),\n",
        "    RegularizedDense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw41o5NRbADN",
        "outputId": "0001cc2a-8f55-4f7e-f501-181c5b783216"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 14s 7ms/step - loss: 1.6722 - accuracy: 0.8124 - val_loss: 0.7165 - val_accuracy: 0.8294\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.7221 - accuracy: 0.8263 - val_loss: 0.6812 - val_accuracy: 0.8426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 드롭아웃"
      ],
      "metadata": {
        "id": "glfTHwaEbC6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1UxQz3EbCQN",
        "outputId": "241e2674-2d34-48d7-dcba-aaa0c6a6236f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.5768 - accuracy: 0.8033 - val_loss: 0.3694 - val_accuracy: 0.8670\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.4181 - accuracy: 0.8458 - val_loss: 0.3357 - val_accuracy: 0.8704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 알파 드롭아웃 - SELU에서는 드롭아웃이 네트워크의 자기 정규화를 망칠 수 있어, 알파 드롭아웃을 사용해야 함."
      ],
      "metadata": {
        "id": "tDmaacDlbHO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 20\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL8ofQ0lbEjK",
        "outputId": "61a1d720-f966-457a-8b60-77a24ca4b6ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6662 - accuracy: 0.7590 - val_loss: 0.5307 - val_accuracy: 0.8478\n",
            "Epoch 2/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5560 - accuracy: 0.7955 - val_loss: 0.5249 - val_accuracy: 0.8538\n",
            "Epoch 3/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5246 - accuracy: 0.8070 - val_loss: 0.5664 - val_accuracy: 0.8470\n",
            "Epoch 4/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5029 - accuracy: 0.8129 - val_loss: 0.4537 - val_accuracy: 0.8640\n",
            "Epoch 5/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4927 - accuracy: 0.8183 - val_loss: 0.4718 - val_accuracy: 0.8612\n",
            "Epoch 6/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4794 - accuracy: 0.8233 - val_loss: 0.4679 - val_accuracy: 0.8606\n",
            "Epoch 7/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4685 - accuracy: 0.8253 - val_loss: 0.4438 - val_accuracy: 0.8616\n",
            "Epoch 8/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4648 - accuracy: 0.8289 - val_loss: 0.4568 - val_accuracy: 0.8660\n",
            "Epoch 9/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4590 - accuracy: 0.8295 - val_loss: 0.4473 - val_accuracy: 0.8756\n",
            "Epoch 10/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4510 - accuracy: 0.8307 - val_loss: 0.4408 - val_accuracy: 0.8714\n",
            "Epoch 11/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4470 - accuracy: 0.8356 - val_loss: 0.4603 - val_accuracy: 0.8674\n",
            "Epoch 12/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4431 - accuracy: 0.8351 - val_loss: 0.4450 - val_accuracy: 0.8742\n",
            "Epoch 13/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4426 - accuracy: 0.8353 - val_loss: 0.4165 - val_accuracy: 0.8754\n",
            "Epoch 14/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4351 - accuracy: 0.8379 - val_loss: 0.4170 - val_accuracy: 0.8722\n",
            "Epoch 15/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4364 - accuracy: 0.8363 - val_loss: 0.4332 - val_accuracy: 0.8768\n",
            "Epoch 16/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4308 - accuracy: 0.8413 - val_loss: 0.4517 - val_accuracy: 0.8678\n",
            "Epoch 17/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4276 - accuracy: 0.8412 - val_loss: 0.4219 - val_accuracy: 0.8764\n",
            "Epoch 18/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4245 - accuracy: 0.8424 - val_loss: 0.4899 - val_accuracy: 0.8684\n",
            "Epoch 19/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4218 - accuracy: 0.8429 - val_loss: 0.4223 - val_accuracy: 0.8776\n",
            "Epoch 20/20\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4187 - accuracy: 0.8451 - val_loss: 0.4907 - val_accuracy: 0.8692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jQimJSvbSVn",
        "outputId": "c6b2772f-117e-4319-99e0-bbeebd32d205"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.8573\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5219749808311462, 0.8572999835014343]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bajDfvMMbU6A",
        "outputId": "a9f96520-a109-4335-fad0-1710e5c1c14b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3981 - accuracy: 0.8776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3980788588523865, 0.8776181936264038]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVZyEBWcbV0y",
        "outputId": "33ef8f04-0610-4bfd-d07e-629870a039bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4184 - accuracy: 0.8439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 몬테카를로 드롭아웃"
      ],
      "metadata": {
        "id": "F5WM93SYbWtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probas = np.stack([model(X_test_scaled, training=True)\n",
        "                     for sample in range(100)])\n",
        "y_proba = y_probas.mean(axis=0)\n",
        "y_std = y_probas.std(axis=0)"
      ],
      "metadata": {
        "id": "07Ia056IbWW3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(model.predict(X_test_scaled[:1]), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_eKFDBSbZls",
        "outputId": "8a1ddc59-3248-4c4a-9f7f-ee388f5f0041"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_probas[:, :1], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyCfn9CTbaOq",
        "outputId": "e90951e8-8904-43c2-d653-4bd580c6d031"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.9 , 0.  , 0.02, 0.  , 0.08]],\n",
              "\n",
              "       [[0.  , 0.  , 0.01, 0.  , 0.01, 0.16, 0.01, 0.2 , 0.  , 0.62]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.16, 0.  , 0.57]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.08, 0.  , 0.84]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.69, 0.  , 0.29]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.  , 0.37, 0.  , 0.1 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.02, 0.  , 0.68]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
              "\n",
              "       [[0.01, 0.  , 0.04, 0.  , 0.02, 0.1 , 0.06, 0.31, 0.02, 0.42]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.73]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.07, 0.  , 0.83]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.93]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.72]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.91, 0.  , 0.08]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.9 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.08, 0.  , 0.89]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.82]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.25, 0.  , 0.73]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.37, 0.  , 0.61]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.52, 0.  , 0.29]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.1 , 0.  , 0.66]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.01, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.24, 0.  , 0.54]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.78]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.32, 0.  , 0.62]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.17, 0.  , 0.79]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.95]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.03, 0.  , 0.93]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.01, 0.  , 0.91]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.84]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.28, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.57]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.89]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.04, 0.  , 0.63]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.36, 0.  , 0.59]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.8 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.9 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.58, 0.  , 0.35]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.49, 0.  , 0.37]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.53, 0.  , 0.29]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.11, 0.  , 0.83]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.73]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.29, 0.  , 0.49]],\n",
              "\n",
              "       [[0.  , 0.  , 0.02, 0.  , 0.02, 0.13, 0.  , 0.03, 0.  , 0.79]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.17, 0.  , 0.78]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.02, 0.  , 0.91]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.18, 0.  , 0.81]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.84, 0.  , 0.13]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.14, 0.  , 0.81]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.69, 0.  , 0.25]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.11, 0.  , 0.84]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.89, 0.  , 0.02, 0.  , 0.09]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.64, 0.  , 0.29]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.88]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.13, 0.  , 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.11, 0.  , 0.87]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.89]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.38, 0.  , 0.61]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.86]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_std = y_probas.std(axis=0)\n",
        "np.round(y_std[:1], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4yHHwTfba6A",
        "outputId": "79bff772-f547-4f30-e749-724075f7f78a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.01, 0.19, 0.  , 0.25]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_proba, axis=1)"
      ],
      "metadata": {
        "id": "LZhlgAPob-OF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8cyaw-yb-At",
        "outputId": "86816ad0-a456-483b-af92-75067158ef1c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8685"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MCDropout(keras.layers.Dropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "\n",
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "EKEVuDw-cCjO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    MCAlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    MCAlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    MCAlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 20\n",
        "history = mc_model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-3sHY4bcCeM",
        "outputId": "45bd08a6-3fbc-41b9-bee1-1bf2b858721d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6617 - accuracy: 0.7592 - val_loss: 0.5748 - val_accuracy: 0.7960\n",
            "Epoch 2/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5546 - accuracy: 0.7974 - val_loss: 0.5578 - val_accuracy: 0.7884\n",
            "Epoch 3/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.5251 - accuracy: 0.8051 - val_loss: 0.5065 - val_accuracy: 0.8134\n",
            "Epoch 4/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.5050 - accuracy: 0.8123 - val_loss: 0.4866 - val_accuracy: 0.8246\n",
            "Epoch 5/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4910 - accuracy: 0.8181 - val_loss: 0.4908 - val_accuracy: 0.8326\n",
            "Epoch 6/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4829 - accuracy: 0.8218 - val_loss: 0.4655 - val_accuracy: 0.8288\n",
            "Epoch 7/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4738 - accuracy: 0.8234 - val_loss: 0.4771 - val_accuracy: 0.8214\n",
            "Epoch 8/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4657 - accuracy: 0.8264 - val_loss: 0.4742 - val_accuracy: 0.8260\n",
            "Epoch 9/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4589 - accuracy: 0.8296 - val_loss: 0.4848 - val_accuracy: 0.8236\n",
            "Epoch 10/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4497 - accuracy: 0.8341 - val_loss: 0.4598 - val_accuracy: 0.8362\n",
            "Epoch 11/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4482 - accuracy: 0.8344 - val_loss: 0.4604 - val_accuracy: 0.8258\n",
            "Epoch 12/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4423 - accuracy: 0.8361 - val_loss: 0.4765 - val_accuracy: 0.8412\n",
            "Epoch 13/20\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4405 - accuracy: 0.8379 - val_loss: 0.4693 - val_accuracy: 0.8398\n",
            "Epoch 14/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4386 - accuracy: 0.8361 - val_loss: 0.4488 - val_accuracy: 0.8364\n",
            "Epoch 15/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4347 - accuracy: 0.8385 - val_loss: 0.4575 - val_accuracy: 0.8334\n",
            "Epoch 16/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4290 - accuracy: 0.8404 - val_loss: 0.4593 - val_accuracy: 0.8368\n",
            "Epoch 17/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4299 - accuracy: 0.8405 - val_loss: 0.4482 - val_accuracy: 0.8420\n",
            "Epoch 18/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4252 - accuracy: 0.8416 - val_loss: 0.4432 - val_accuracy: 0.8418\n",
            "Epoch 19/20\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4238 - accuracy: 0.8438 - val_loss: 0.4448 - val_accuracy: 0.8450\n",
            "Epoch 20/20\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4211 - accuracy: 0.8432 - val_loss: 0.4335 - val_accuracy: 0.8372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmNk0UbBcCOv",
        "outputId": "662f5e22-c57e-440a-e94a-c5c75d19be11"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " mc_alpha_dropout (MCAlphaDr  (None, 784)              0         \n",
            " opout)                                                          \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 300)               235500    \n",
            "                                                                 \n",
            " mc_alpha_dropout_1 (MCAlpha  (None, 300)              0         \n",
            " Dropout)                                                        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " mc_alpha_dropout_2 (MCAlpha  (None, 100)              0         \n",
            " Dropout)                                                        \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rezin0W7cCL_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model.set_weights(model.get_weights())"
      ],
      "metadata": {
        "id": "KVHePoE4cHR9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AEpyVJecHOd",
        "outputId": "7a3f185e-ba93-4f41-ad2e-709335bb4f6a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.44, 0.  , 0.44]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 맥스 노름 - 가중치가 일정 범위 이상으로 높아지는 것을 방지"
      ],
      "metadata": {
        "id": "8H71jA7fbksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))"
      ],
      "metadata": {
        "id": "yW1MNba1blcy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MaxNormDense = partial(keras.layers.Dense,\n",
        "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    MaxNormDense(300),\n",
        "    MaxNormDense(100),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl8LpGPHbm3l",
        "outputId": "ac97af7f-fc9f-4693-f5ee-6ecf7f070f20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 14s 7ms/step - loss: 0.4734 - accuracy: 0.8337 - val_loss: 0.3756 - val_accuracy: 0.8654\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3579 - accuracy: 0.8689 - val_loss: 0.3890 - val_accuracy: 0.8584\n"
          ]
        }
      ]
    }
  ]
}